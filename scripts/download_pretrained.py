# scripts/download_pretrained.py - ä¿®å¤ç‰ˆæœ¬
import os
import requests
import torch
import zipfile
import gdown
from pathlib import Path
import json
import shutil

def download_ppo_models():
    """ä¸‹è½½PPOé¢„è®­ç»ƒæ¨¡å‹ - ä¿®å¤ç‰ˆæœ¬"""
    
    # ä½¿ç”¨æ›´å¯é çš„æ¨¡å‹æº
    ppo_sources = {
        'HalfCheetah': 'https://huggingface.co/edbeeching/ppo-HalfCheetah-v3/resolve/main/ppo-HalfCheetah-v3.pt',
        'Ant': 'https://huggingface.co/edbeeching/ppo-Ant-v3/resolve/main/ppo-Ant-v3.pt',
        'Hopper': 'https://huggingface.co/edbeeching/ppo-Hopper-v3/resolve/main/ppo-Hopper-v3.pt',
        'Walker2d': 'https://huggingface.co/edbeeching/ppo-Walker2d-v3/resolve/main/ppo-Walker2d-v3.pt'
    }
    
    save_dir = Path("data/pretrained/source_policies")
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # ç¬¬ä¸€æ­¥ï¼šå¤‡ä»½æˆ–åˆ é™¤ç°æœ‰çš„æµ‹è¯•ç­–ç•¥
    backup_test_policies(save_dir)
    
    for robot_type, url in ppo_sources.items():
        filename = save_dir / f"{robot_type.lower()}_policy.pth"
        temp_filename = save_dir / f"{robot_type.lower()}_downloading.pth"
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯çœŸå®æ¨¡å‹ï¼ˆä¸æ˜¯æµ‹è¯•ç­–ç•¥ï¼‰
        if filename.exists():
            if is_real_model(filename):
                print(f"âœ“ {robot_type} real model already exists, skipping download")
                continue
            else:
                print(f"ğŸ”„ {robot_type} test model exists, replacing with real model")
                # å¤‡ä»½æµ‹è¯•æ¨¡å‹
                backup_path = save_dir / f"{robot_type.lower()}_test_backup.pth"
                shutil.move(filename, backup_path)
                print(f"  Backed up test model to {backup_path}")
        
        print(f"Downloading {robot_type} model...")
        try:
            # ä½¿ç”¨requestsä¸‹è½½
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(url, stream=True, headers=headers, timeout=30)
            response.raise_for_status()
            
            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            with open(temp_filename, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            
            # éªŒè¯æ–‡ä»¶
            if validate_model_file(temp_filename):
                # é‡å‘½åä¸ºæ­£å¼æ–‡ä»¶
                shutil.move(temp_filename, filename)
                print(f"âœ“ Downloaded {robot_type} model successfully")
                
                # åˆ›å»ºå…¼å®¹ç‰ˆæœ¬
                create_compatible_model(robot_type, filename)
            else:
                print(f"âš ï¸  {robot_type} model validation failed")
                if filename.exists():
                    os.remove(filename)
                create_fallback_model(robot_type, filename)
                
        except Exception as e:
            print(f"âœ— Failed to download {robot_type}: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_filename.exists():
                os.remove(temp_filename)
            # æ¢å¤æµ‹è¯•æ¨¡å‹æˆ–åˆ›å»ºå›é€€
            if not filename.exists():
                restore_test_policy(robot_type, save_dir)

def is_real_model(filepath: Path) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯çœŸå®æ¨¡å‹ï¼ˆä¸æ˜¯æµ‹è¯•ç­–ç•¥ï¼‰"""
    try:
        checkpoint = torch.load(filepath, map_location='cpu', weights_only=False)
        
        # æµ‹è¯•ç­–ç•¥çš„æ ‡è¯†
        if isinstance(checkpoint, dict):
            if checkpoint.get('is_test_policy', False):
                return False
            if checkpoint.get('is_fallback', False):
                return False
            # çœŸå®æ¨¡å‹åº”è¯¥æœ‰å®é™…çš„ç½‘ç»œæƒé‡
            if 'actor' in checkpoint or 'policy' in checkpoint or 'model_state_dict' in checkpoint:
                return True
        
        return True  # é»˜è®¤è®¤ä¸ºæ˜¯çœŸå®æ¨¡å‹
    except:
        return False

def backup_test_policies(save_dir: Path):
    """å¤‡ä»½ç°æœ‰çš„æµ‹è¯•ç­–ç•¥"""
    print("Checking for existing test policies...")
    
    test_robots = ['halfcheetah', 'ant', 'hopper', 'walker2d']
    
    for robot in test_robots:
        policy_path = save_dir / f"{robot}_policy.pth"
        if policy_path.exists() and is_test_policy(policy_path):
            backup_path = save_dir / f"{robot}_test_backup.pth"
            shutil.copy2(policy_path, backup_path)
            print(f"  Backed up test policy for {robot}")

def is_test_policy(filepath: Path) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•ç­–ç•¥"""
    try:
        checkpoint = torch.load(filepath, map_location='cpu', weights_only=False)
        return checkpoint.get('is_test_policy', False) or checkpoint.get('is_fallback', False)
    except:
        return False

def restore_test_policy(robot_type: str, save_dir: Path):
    """æ¢å¤æµ‹è¯•ç­–ç•¥ï¼ˆå½“ä¸‹è½½å¤±è´¥æ—¶ï¼‰"""
    backup_path = save_dir / f"{robot_type.lower()}_test_backup.pth"
    policy_path = save_dir / f"{robot_type.lower()}_policy.pth"
    
    if backup_path.exists():
        shutil.copy2(backup_path, policy_path)
        print(f"  Restored test policy for {robot_type}")
    else:
        # åˆ›å»ºæ–°çš„æµ‹è¯•ç­–ç•¥
        create_test_policy(robot_type, save_dir)

def create_test_policy(robot_type: str, save_dir: Path):
    """åˆ›å»ºå•ä¸ªæµ‹è¯•ç­–ç•¥"""
    filename = save_dir / f"{robot_type.lower()}_policy.pth"
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•ç­–ç•¥
    test_policy = {
        'policy_state_dict': {
            'propagation_network.0.weight': torch.randn(256, 17) * 0.1,
            'propagation_network.0.bias': torch.randn(256) * 0.1,
            'propagation_network.2.weight': torch.randn(256, 256) * 0.1,
            'propagation_network.2.bias': torch.randn(256) * 0.1,
            'simple_output.0.weight': torch.randn(256, 256) * 0.1,
            'simple_output.0.bias': torch.randn(256) * 0.1,
            'simple_output.2.weight': torch.randn(12, 256) * 0.1,
            'simple_output.2.bias': torch.randn(12) * 0.1,
        },
        'robot_type': robot_type,
        'is_test_policy': True,
        'performance_level': 'basic'
    }
    
    torch.save(test_policy, filename)
    print(f"âœ“ Created test policy for {robot_type}")

# å…¶ä»–å‡½æ•°ä¿æŒä¸å˜...
def validate_model_file(filepath: Path) -> bool:
    """éªŒè¯æ¨¡å‹æ–‡ä»¶æ ¼å¼"""
    try:
        checkpoint = torch.load(filepath, map_location='cpu', weights_only=False)
        
        if isinstance(checkpoint, dict):
            valid_keys = ['actor', 'critic', 'policy', 'model_state_dict', 'state_dict']
            if any(key in checkpoint for key in valid_keys):
                return True
        
        return False
        
    except Exception as e:
        print(f"  Validation failed: {e}")
        return False

def create_compatible_model(robot_type: str, original_filepath: Path):
    """åˆ›å»ºå…¼å®¹çš„æ¨¡å‹æ ¼å¼"""
    try:
        original_checkpoint = torch.load(original_filepath, map_location='cpu', weights_only=False)
        
        compatible_checkpoint = {
            'policy_state_dict': extract_policy_weights(original_checkpoint),
            'robot_type': robot_type,
            'source': 'huggingface',
            'compatible_format': True
        }
        
        compatible_path = original_filepath.parent / f"{robot_type.lower()}_compatible.pth"
        torch.save(compatible_checkpoint, compatible_path)
        print(f"âœ“ Created compatible model for {robot_type}")
        
    except Exception as e:
        print(f"âœ— Failed to create compatible model: {e}")

def extract_policy_weights(checkpoint: dict) -> dict:
    """ä»æ£€æŸ¥ç‚¹æå–ç­–ç•¥æƒé‡"""
    policy_weights = {}
    
    if 'actor' in checkpoint:
        actor_weights = checkpoint['actor']
        for key, value in actor_weights.items():
            if 'pi' in key or 'actor' in key:
                new_key = key.replace('pi_features_extractor.', '').replace('pi_', '')
                policy_weights[new_key] = value
                
    elif 'policy' in checkpoint:
        policy_weights = checkpoint['policy']
        
    elif 'model_state_dict' in checkpoint:
        policy_weights = checkpoint['model_state_dict']
        
    else:
        policy_weights = checkpoint
    
    return policy_weights

def create_fallback_model(robot_type: str, filepath: Path):
    """åˆ›å»ºå›é€€æ¨¡å‹"""
    print(f"  Creating fallback model for {robot_type}")
    
    fallback_weights = {
        'propagation_network.0.weight': torch.randn(256, 17) * 0.01,
        'propagation_network.0.bias': torch.randn(256) * 0.01,
        'propagation_network.2.weight': torch.randn(256, 256) * 0.01,
        'propagation_network.2.bias': torch.randn(256) * 0.01,
        'simple_output.0.weight': torch.randn(256, 256) * 0.01,
        'simple_output.0.bias': torch.randn(256) * 0.01,
        'simple_output.2.weight': torch.randn(12, 256) * 0.01,
        'simple_output.2.bias': torch.randn(12) * 0.01,
        'robot_type': robot_type,
        'is_fallback': True
    }
    
    torch.save(fallback_weights, filepath)

def verify_pretrained_models():
    """éªŒè¯é¢„è®­ç»ƒæ¨¡å‹"""
    models_dir = Path("data/pretrained/source_policies")
    
    expected_models = ['halfcheetah', 'ant', 'hopper', 'walker2d']
    
    print("\nğŸ” Verifying models...")
    for model_name in expected_models:
        model_path = models_dir / f"{model_name}_policy.pth"
        
        if model_path.exists():
            try:
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
                
                if checkpoint.get('is_test_policy', False):
                    print(f"âš ï¸  {model_name}: TEST POLICY (limited performance)")
                elif checkpoint.get('is_fallback', False):
                    print(f"âš ï¸  {model_name}: FALLBACK MODEL (basic functionality)")
                elif checkpoint.get('compatible_format', False):
                    print(f"âœ“ {model_name}: REAL MODEL (compatible format)")
                elif 'actor' in checkpoint or 'policy' in checkpoint:
                    print(f"âœ“ {model_name}: REAL MODEL (original format)")
                else:
                    print(f"â“ {model_name}: Unknown format")
                    
            except Exception as e:
                print(f"âœ— {model_name}: Corrupted file - {e}")
        else:
            print(f"âœ— {model_name}: Missing file")

if __name__ == "__main__":
    
    print("ğŸš€ Starting pretrained model setup...")
    
    # ç›´æ¥ä¸‹è½½çœŸå®æ¨¡å‹ï¼Œä¸å…ˆåˆ›å»ºæµ‹è¯•ç­–ç•¥
    download_ppo_models()
    
    # éªŒè¯æ‰€æœ‰æ¨¡å‹
    verify_pretrained_models()
    
    print("Models are ready for use!")